\chapter{Conclusión}
\label{Conclusión}
\section{Introducción}

En el presente proyecto, se realizó un estudio profundo sobre Machine Learning, sus conceptos más importantes como también sus diferentes aplicaciones y casos de uso. Se comparó y probó diferentes algoritmos de Machine Learning. Luego, se eligió el modelo YOLOv5 de los analizados para probar su funcionamiento en un caso práctico de Computer Vision. Se investigó la utilidad de este modelo para detección de imágenes en tiempo real y se llegó a la conclusión de que es muy útil y puede ser aplicado a diferentes problemas. Como lo es en nuestro caso el análisis de Imágenes satelitales y así detectar el abuso de los recursos hídricos, evasión impositivas en el rubro agropecuario, deforestaciones, asentamientos y expropiaciones ilegales, entre otros, mediante la detección de pivotes de riego y silobolsas en campos.

El conocimiento adquirido a lo largo de la carrera, en las materias tales como Arquitectura de Computadoras y Sistemas Operativos, formó una base de conocimiento imprescindible para el desarrollo del proyecto. Los problemas que se plantearon pudieron ser abarcados gracias a la preparación recibida en la facultad, a la formación e investigación realizada sobre Deep Learning, Computer Vision, Redes Neuronales, entre otros, junto con paciencia, perseverancia y curiosidad.

El objetivo era desarrollar y aplicar éstos conocimientos para ayudar al medio ambiente o proveer alguna herramienta que sea útil para el mismo, y que pueda ser usado por cualquier persona interesada sin costo alguno y hacer un aporte de Machine Learning al ámbito publico. 

\subsection{Problemas y Limitaciones}
A continuación, se elaboran algunos problemas y limitaciones que se presentaron durante el desarrollo del proyecto.
\begin{itemize}
        \item \textit{Investigación}: \\
            Antes de elegir el modelo adecuado en base a una opinión apta, se debió contar con suficiente información y conocimiento en materia de Machine Learning, para comprender como funcionan las Redes Neuronales y todo lo que hay detrás de ellas para su funcionamiento. Conocimiento que al momento de empezar este proyecto no se contaba a fondo. El camino comenzó con un curso de Coursera \cite{coursera}, dictado por el Dr. Andrew Ng, el cual allanó el camino para conocer en detalle qué es y cómo funciona Machine Learning. También introdujo los primeros conceptos a cerca de los cimientos de YOLO. Se profundizó el estudio con la lectura de los papers oficiales de YOLOv1, YOLOv2 y YOLOv3, (y más adelante, YOLOv4 y YOLOv5). Se complementó la investigación con el estudio de técnicas para mejorar los resultados de inferencia: purga de dataset, data augmentation, transfer learning, seteo de hiper-parámetros, recomendaciones en cuanto a la duración de las epochs, entre otros. Por otro lado, se investigó en materia de métricas y creación y análisis de gráficas para detectar tempranamente posibles puntos de overfit o bien detectar la posibilidad de continuar entrenando. El estudio de métricas tales como precisión, recall, F1 Score, Mean Average Precision (mAP), mAP con barrido de IoU, matriz de confusión y correlograma de etiquetas, por nombrar algunos. La selección de las métricas a utilizar no fue trivial, se compararon varias métricas para medir la performance del modelo y dada la naturaleza del dataset se hizo un descarte de las métricas que no aportaban mucha información.
            
            A continuación se realizo una lectura y comparación de los distintos frameworks que se disponían en Python para basar el modelo de Redes Neuronales y demás algoritmos y optimizadores que componen un modelo de Machine Learning completo, tales como: PyTorch, TensorFlow y TensorFlow 2.0; optando por Tensorflow en su versión vainilla dada su mayor trayectoria en la industria, educación e investigación y la abundante documentación disponible en la web. Sin embargo, más avanzado en el proyecto y obligados a cambiar de modelo, al migrar a la versión más reciente de YOLOv5, gran parte de su mejora de performance se debía a su implementación en PyTorch, framework el cual, en el transcurso de los meses que pasaron desde el comienzo de este proyecto y el momento de su selección, había madurado considerablemente y resultaba un opción más que válida. \\
        
        \item \textit{Preparación del entorno de trabajo}: \\
            El proyecto fue desarrollado principalmente en la súper computadora (cluster) de la Facultad de Ciencias Exactas, Físicas y Naturales denominada: Nabucodonosor, ya que ofrecía suficiente poder de cómputo y almacenamiento para soportar los entrenamientos requeridos para obtener los resultados deseados, así como también la disponibilidad 24/7 para dejar corriendo scripts de diferente índole (ej.: data augmentation). No obstante, la computadora ofreció tempranamente algunos problemas al momento de setear el entorno de trabajo. Se tuvieron limitaciones para la conexión vía túnel SSH para hacer uso de la consola, conexión la cual una vez lograda, tenia la limitación de no ofrecer interfaz gráfica para algunas features que ofrecían los modelos descargados.
            Por otro lado, también hubo dificultades para lograr configurar un contenedor Docker el cual permitiera el uso completo del hardware que el clúster tenia disponible. Finalmente, por cuestiones de seguridad, el acceso a la página web con la interfaz visual para este proyecto se vio limitado a ser vía túnel SSH, esfumando la posibilidad de ofrecer un endpoint de publico acceso.
            Otro tema que causó algunas limitaciones fueron los inesperados cortes de luz que sufría la facultad, lo cual dejaba inaccesible el clúster hasta su reinicio de manera manual. Impactando la disponibilidad, también se vio agregado la cola de espera para hacer uso de la maquina, dado que es un recurso compartido por todo el ámbito de la educación e investigación del país. \\
        
        \item \textit{Elaboración del dataset}: \\
            Este paso fue uno de los mas importante, por que influye significativamente en el entrenamiento del algoritmo, por que se alimenta y aprende a través de las imágenes que se le entregan. Es por eso que las mismas deben ser cuidadosamente elegidas, haciendo foco en el objeto que se quiere detectar y con una gran variedad de los mismos. En este paso, se cometieron algunos errores al momento de elegirlos debido a la diferencia de tamaño que hay entre los objetos en cuestión, al principio no fueron lo suficientemente grandes o centrados, y dicha mala elección se vio reflejada en los resultados de detección que se obtenían. Es por eso que se invirtió suficiente tiempo en preparar el conjunto de datos, con el tamaño correcto de la imagen y el objeto en la misma, diferencias de colores, fondos y texturas para hacer mas variado el conjunto. \\
            
        \item \textit{Análisis y elección del algoritmo}: \\
            Al momento de la realización de este trabajo se investigó sobre los algoritmos de Computer Vision en tiempo real más populares y que sea aplicable a éste proyecto. Al principio se optó por el algoritmo YOLOv3, el cual era el estado del arte al comenzar el proyecto. El modelo prometía tiempos de inferencia muy rápidos, categorizándolo como un algoritmo de detección en tiempo real, la posibilidad de hacer transfer learning, y ajustar el modelo a un dataset personalizado. Tras familiarizarse con el modelo y la especificación para el etiquetado, se realizaron las primeras pruebas preliminares con un dataset personalizado que incluyera dos clases. Esto arrojó en principio resultados prometedores, sin embargo, aun lejos de lograr la precisión deseada. Se procedió, entonces, a incrementar el tamaño del dataset, purgarlo y diversificarlo, pero sin lograr los resultados esperados. Se realizaron barridos en los hiper-parámetros que el modelo hacia disponible, pero sin grandes mejoras. Se prosiguió con una alteración directa al código fuente del modelo, agregando nuevos y variados optimizadores para mejorar la performance de la función de costo. Se calcularon nuevos anchor boxes, tanto elegidos a mano como mediante el uso de el algoritmo K-Means. Ambos ensayos tuvieron un impacto casi nulo en la performance del modelo. Tras meses de ensayos, se tomó la decisión de buscar otro código fuente o bien otro modelo, lo que dio como resultado el descubrimiento de una nueva y mejorada versión de YOLOv3: YOLOv5. El mismo otorgó, desde las primeras pruebas, mayor facilidad para el seteo de su entorno, soportaba el mismo dataset que se venia utilizando en YOLOv3 y brindó resultados excelentes, llegando incluso a superar las expectativas.
        
 \end{itemize}

\subsection{Trabajos futuros}
La aplicación final presentada como una página web, permite al usuario final hacer uso de un modelo funcional mediante una interfaz gráfica familiar. Los resultados finales son aceptables pero distan de la excelencia, aun así, conforman una base sólida para ser mejorados en proyectos futuros, por ejemplo, mejorando el dataset y re-entrenando por más tiempo, realizando un cambio de modelo base, por nombrar algunas ideas. Por otro lado, el software presentado como un backend y frontend permiten ser modificados con facilidad por los futuros desarrolladores que continúen con este trabajo.
\subsection{Aporte personal}

El conocimiento adquirido a lo largo de la carrera Ingeniería en Computación, en especial en materias tales como Redes de Computadoras, Sistemas Operativos y Sistemas de Computación, fueron fundamentales para formar una base sólida para desarrollar este proyecto. Si bien el tema principal no es abarcado como materia tal en la carrera, la problemática que se plateo pudo ser resuelta gracias a la preparación recibida por la facultad y nuestros profesores, junto con la curiosidad, paciencia y perseverancia, se logró alcanzar los objetivos planteados.

\newpage
